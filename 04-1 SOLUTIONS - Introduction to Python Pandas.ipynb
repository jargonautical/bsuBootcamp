{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTIONS\n",
    "### Task 1 - Installing and Importing Modules (Pandas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write a command to install the pandas library in your environment.\n",
    "\n",
    "Note: It’s important to install pandas because it provides data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "Python raw would not need the % or !\n",
    "Depending on the verison of Jupyter Notebook a % or ! will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a command to install a specific version (2.1.1) of pandas.\n",
    "\n",
    "Note: Sometimes, you might need to work with a specific version of pandas due to compatibility issues with other libraries or specific features available in that version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas==2.1.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a command to import the pandas library as ‘pd’.\n",
    "\n",
    "Note: It’s a common convention to import pandas as pd. This makes your code shorter and more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write a command to create a pandas Series named ‘fruits’ with the values [‘apple’, ‘banana’, ‘cherry’].\n",
    "\n",
    "Note: A Series is a one-dimensional labeled array capable of holding any data type. It is one of the basic structures in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fruits = pd.Series(['apple', 'banana', 'cherry'])\n",
    "\n",
    "print(fruits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Create a DataFrame named ‘purchases’ with two columns ‘apples’ and ‘oranges’.\n",
    "\n",
    "```\n",
    "The ‘apples’ column should have the values [3, 2, 0, 1] and the ‘oranges’ column should have the values [0, 3, 7, 2].\n",
    "```\n",
    "\n",
    "Note: DataFrames are two-dimensional size-mutable, potentially heterogeneous tabular data structures with labeled axes (rows and columns). They are one of the fundamental structures in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   apples  oranges\n",
      "0       3        0\n",
      "1       2        3\n",
      "2       0        7\n",
      "3       1        2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'apples': [3, 2, 0, 1], \n",
    "    'oranges': [0, 3, 7, 2]\n",
    "}\n",
    "\n",
    "purchases = pd.DataFrame(data)\n",
    "\n",
    "print(purchases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Data Loading in Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write a line of code to open the ‘employees.csv’ data file into a pandas DataFrame.\n",
    "\n",
    "```\n",
    "The employees.csv file will need to be in the same directory(folder) as the notebook, or the filepath will need to be added.\n",
    "```\n",
    "\n",
    "Note: This function is useful for loading CSV data into a pandas DataFrame, which is a two-dimensional labeled data structure with columns of potentially different types. It’s one of the most common initial steps in data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('employees.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a line of code to display the first 5 rows of the DataFrame.\n",
    "\n",
    "Note: The .head(n) function is useful for quickly previewing the first n rows of your DataFrame, which can help you get a sense of your data at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)\n",
    "# or print(df.head(5))\n",
    "# will show a less formatted verison of the output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a line of code to display the last 3 rows of the DataFrame.\n",
    "\n",
    "Note: The .tail(n) function is useful for quickly viewing the last n rows of your DataFrame. This can be particularly helpful when you want to see the most recent entries in a time-series dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write a line of code to randomly select 7 rows from the DataFrame.\n",
    "\n",
    "Note: The .sample(n) function is useful when you want to randomly select n rows from your DataFrame. This can be helpful for creating random samples from your data for tasks like bootstrapping or cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write a line of code to save the DataFrame back to a new CSV file named ‘new_employees.csv’.\n",
    "\n",
    "```\n",
    "df.to_csv('new_employees.csv', index=False)\n",
    "```\n",
    "\n",
    "index=False tells the function not to write the row index to file.\n",
    "\n",
    "Note: The .to_csv() function is useful for saving your DataFrame back to a CSV file. This is often used after you’ve made some modifications to your data and want to save the results for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new_employees.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Write a line of code to open a CSV file named ‘separator.csv’ that uses a semicolon (;) as the separator.\n",
    "\n",
    "Note: In CSV files, a separator (also known as a delimiter) is used to distinguish between different fields.\n",
    "\n",
    "The most common separator is a comma, but other characters can be used as well, such as semicolons, tabs (\\t), spaces, etc.\n",
    "\n",
    "The choice of separator can depend on the data itself (for example, if the data contains commas within fields, a different separator might be used).\n",
    "\n",
    "When reading a CSV file with pandas, you can specify the separator using the sep parameter in the read_csv function.\n",
    "\n",
    "If not specified, pandas will assume the separator is a comma.\n",
    "\n",
    "It’s important to know what separator is used in your data file to correctly load it into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "separator_df = pd.read_csv('separator.csv', sep=';')\n",
    "separator_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Write a line of code to get the shape of the DataFrame.\n",
    "\n",
    "Note: The .shape attribute is useful for quickly finding out how many rows and columns are in your DataFrame. It returns a tuple in the format (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Write a line of code to get a summary of the DataFrame’s numerical columns.\n",
    "\n",
    "Note: The .describe() function is useful for quickly generating descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset’s distribution. It automatically excludes NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Write a line of code to get a concise summary of the DataFrame.\n",
    "\n",
    "Note: The .info() function is useful for getting a quick description of the data, especially the total number of non-null observations and the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Write a line of code to get the number of unique values in each column.\n",
    "\n",
    "Note: The .nunique() function is useful for understanding the number of distinct values in each column. This can help identify columns with high cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Write a line of code to select all data from the ‘Age’ column.\n",
    "\n",
    "Note: Selecting a single column from your DataFrame is useful when you want to analyze or manipulate that specific column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12.  Write a line of code to calculate the mean age.\n",
    "\n",
    "Note: The .mode() function is used to find the most frequently occurring value(s) in a series. This can be useful when analyzing categorical data or certain types of numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].mode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. Write a line of code to find the median salary.\n",
    "\n",
    "Note: The .median() function is used to find the middle value in a series when it’s sorted in ascending order. This can be more informative than the mean for datasets with skewed distributions or outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Salary'].median()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Data Cleaning in Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write a line of code to drop the ‘column1’ from the DataFrame.\n",
    "\n",
    "Note: The .drop() function is useful for removing rows or columns by label names and corresponding axis, or by specifying directly index or column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['column1'])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a line of code to fill missing values in the ‘Age’ column with the average age.\n",
    "\n",
    "```\n",
    "This demonstrates the function of the mean function and utlises imputation, but does it make sense to create an Employees age from a Mean? In this situation it would be better to request a real age for an employee from the data source, or remove that emplyee if it is histroical data.\n",
    "```\n",
    "\n",
    "Note: The .fillna() function is used to fill NA/NaN values using the specified method which can be a constant or a DataFrame method like mean, median etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a line of code to drop rows with any missing values.\n",
    "\n",
    "Note: The .dropna() function is used to remove missing values. It’s useful when you want to discard any incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write a line of code to find duplicated rows.\n",
    "\n",
    "Note: The .duplicated() function returns a Boolean Series denoting duplicate rows. It’s useful when you want to identify any repeated data in your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write a line of code to drop duplicated rows.\n",
    "\n",
    "Note: The .drop_duplicates() function is used to remove duplicate rows. This is often necessary in data cleaning process to get rid of repeated information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a line of code to replace ‘Illinois’ with ‘IL’ in the ‘State’ column.\n",
    "\n",
    "Note: The .str.replace() function is used to replace a specified phrase with another specified phrase. It’s useful when you want to standardize the data in your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State'] = df['State'].str.replace('Illinois', 'IL')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Write a line of code to find all rows where ‘City’ contains ‘naperville’.\n",
    "\n",
    "Note: The .str.contains() function is used to test if pattern or regex is contained within a string of a Series or Index. It’s useful when you want to filter your data based on certain text criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naperville_rows = df[df['City'].str.contains('naperville', na=False)]\n",
    "naperville_rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Write a line of code to standardize the ‘City’ and ‘State’ columns in the DataFrame. For ‘City’, replace ‘naperville’ with ‘Naperville’, and for ‘State’, replace ‘Illinois’ with ‘IL’.\n",
    "\n",
    "Note: The .str.replace() function is used to replace a specified phrase with another specified phrase. It’s useful when you want to standardise the data in your DataFrame. In this case, we’re using it to ensure that city and state names follow a consistent format. This is an important step in data cleaning, especially when dealing with text data, as it ensures that the same entity is represented in the same way across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising city names\n",
    "df['City'] = df['City'].str.replace('naperville', 'Naperville')\n",
    "\n",
    "# Standardising state names\n",
    "df['State'] = df['State'].str.replace('Illinois', 'IL')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. (OPTIONAL) Write a line of code to standardize the ‘City’ and ‘State’ columns in the DataFrame.\n",
    "\n",
    "Advanced Question. Will go into more in next lesson so do not worry if you cannot complete this one now.\n",
    "\n",
    "```\n",
    "Reload employees.csv in and output solution to a DataFrame named 'city_state_corrected_df'\n",
    "\n",
    "Any Unknown city or states should be filled with an 'Unknown' string.\n",
    "\n",
    "Run the first code block to create mapping dictionaries for States and City. You can choose to use these or manually type out each state and city and what they should be\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City to State mapping\n",
    "city_state = {\n",
    "    'New York': 'New York',\n",
    "    'Buffalo': 'New York',\n",
    "    'Rochester': 'New York',\n",
    "    'Los Angeles': 'California',\n",
    "    'San Francisco': 'California',\n",
    "    'San Diego': 'California',\n",
    "    'Houston': 'Texas',\n",
    "    'San Antonio': 'Texas',\n",
    "    'Dallas': 'Texas',\n",
    "    'Jacksonville': 'Florida',\n",
    "    'Miami': 'Florida',\n",
    "    'Tampa': 'Florida',\n",
    "    'Chicago': 'Illinois',\n",
    "    'Aurora': 'Illinois',\n",
    "    'Naperville': 'Illinois',\n",
    "    'Philadelphia': 'Pennsylvania',\n",
    "    'Pittsburgh': 'Pennsylvania',\n",
    "    'Allentown': 'Pennsylvania',\n",
    "    'Phoenix': 'Arizona',\n",
    "    'Tucson': 'Arizona',\n",
    "    'Mesa': 'Arizona',\n",
    "    'Indianapolis': 'Indiana',\n",
    "    'Fort Wayne': 'Indiana',\n",
    "    'Evansville': 'Indiana'\n",
    "}\n",
    "\n",
    "# Abbreviations for some states\n",
    "state_abbr = {\n",
    "    'New York': 'NY',\n",
    "    'California': 'CA',\n",
    "    'Texas': 'TX',\n",
    "    'Florida': 'FL',\n",
    "    'Illinois': 'IL',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Arizona': 'AZ',\n",
    "    'Indiana': 'IN'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv the employees.csv into the correctly named DataFrame here\n",
    "import pandas as pd\n",
    "df = pd.read_csv('employees.csv')\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip leading/trailing whitespace and capitalize city names\n",
    "df['City'] = df['City'].str.strip().str.title()\n",
    "\n",
    "# Replace city names with standardized state names\n",
    "df['State'] = df['City'].map(city_state)\n",
    "\n",
    "# If 'State' is still None after the mapping, this means the city was not found in the city_state dictionary.\n",
    "# We can assume these are the entries with 'City' being None or whitespace (since we've already cleaned other cities).\n",
    "# We'll replace these with a placeholder value.\n",
    "df['State'] = df['State'].fillna('Unknown')\n",
    "\n",
    "# Strip leading/trailing whitespace and capitalize state names\n",
    "df['State'] = df['State'].str.strip().str.title()\n",
    "\n",
    "# Replace full state names with abbreviations\n",
    "df['State'] = df['State'].map(state_abbr)\n",
    "\n",
    "# If 'State' is still None after the mapping, this means the state was not found in the state_abbr dictionary.\n",
    "# We'll replace these with a placeholder value.\n",
    "df['State'] = df['State'].fillna('Unknown')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. (OPTIONAL) Perform Data Cleaning on the Gender Column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Data Manipulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write a line of code to apply a function that adds 10 to each value in the ‘Age’ column\n",
    "\n",
    "```\n",
    "A lambda function would make the code more readable here.\n",
    "```\n",
    "\n",
    "Note: The .apply() function is useful for applying a function along an axis of the DataFrame. It can be used with a lambda function, as in this case, to perform operations on each element in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['Age'] = df['Age'].apply(lambda x: int(x) + 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a line of code to apply a function that converts all names in the ‘Name’ column to uppercase.\n",
    "\n",
    "Note: The .apply() function can be used with string methods to perform operations on each string in a column, e.g. .upper()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'] = df['Name'].apply(lambda x: x.upper())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a line of code to concatenate df and df2 along rows.\n",
    "\n",
    "```\n",
    "# Creating a second DataFrame\n",
    "data2 = {\n",
    "    'Name': ['John', 'Jane'],\n",
    "    'Age': [30, 25],\n",
    "    'City': ['New York', 'Los Angeles'],\n",
    "    'Salary': [70000, 80000],\n",
    "    'Gender': ['Male', 'Female'],\n",
    "    'column1': ['Doe', 'Doe'],\n",
    "    'State': ['NY', 'CA'],\n",
    "    'Start Date': ['2010-01-01', '2012-07-01'],\n",
    "    'DateOfBirth': ['1990-01-01', '1997-07-01']\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "```\n",
    "\n",
    "Note: The pd.concat() function is useful for concatenating two or more pandas objects along a particular axis. By default, it concatenates along rows (i.e., axis=0). This is often used when you want to append rows from one DataFrame to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the dataframe 1\n",
    "data = {\n",
    "    'Name': ['joseph', 'Joshua', 'yvonne', 'nicole', 'Adam'],\n",
    "    'Age': [44.0, None, 49.0, 27.0, 47.0],\n",
    "    'City': ['naperville', 'aurora', None, 'Rochester', 'fort wayne'],\n",
    "    'Salary': [105000.0, 154000.0, 35000.0, 54000.0, 72000.0],\n",
    "    'Gender': ['other', None, 'Female', 'Other', None],\n",
    "    'column1': ['Holmes', 'Young', 'Martin', 'Zuniga', 'Ramirez'],\n",
    "    'State': ['Illinois', 'Illinois', None, 'New York', 'IN'],\n",
    "    'Start Date': ['2014-10-16', '2002-05-06', '1994', '1999-05-21', '2021-04-10'],\n",
    "    'DateOfBirth': ['1979-10-12', '2023-05-21', '1974-10-13 00:00:00', '1996-10-07', '1976-10-12']\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a second DataFrame\n",
    "data2 = {\n",
    "    'Name': ['John', 'Jane'],\n",
    "    'Age': [30, 25],\n",
    "    'City': ['New York', 'Los Angeles'],\n",
    "    'Salary': [70000, 80000],\n",
    "    'Gender': ['Male', 'Female'],\n",
    "    'column1': ['Doe', 'Doe'],\n",
    "    'State': ['NY', 'CA'],\n",
    "    'Start Date': ['2010-01-01', '2012-07-01'],\n",
    "    'DateOfBirth': ['1990-01-01', '1997-07-01']\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating df and df2 along rows (default axis=0)\n",
    "df3 = pd.concat([df, df2])\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write a line of code to concatenate df and df2 along columns.\n",
    "\n",
    "Note: By specifying axis=1 in the pd.concat() function, you can concatenate DataFrames along columns instead of rows. This is useful when you want to add new columns to a DataFrame from another DataFrame with the same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating df and df2 along columns (axis=1)\n",
    "df3 = pd.concat([df, df2], axis=1)\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write a line of code to concatenate df and df2, and ignore the original index.\n",
    "\n",
    "Note: The ignore_index=True parameter in the pd.concat() function is useful when you want to ignore the original index and reset it in the resulting DataFrame. This is often used when the index does not contain any meaningful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating df and df2 and ignoring the original index\n",
    "df3 = pd.concat([df, df2], ignore_index=True)\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (Homework): Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create dataframes function\n",
    "\n",
    "def create_joins_df():\n",
    "    # Creating DataFrame df1\n",
    "    data1 = {\n",
    "        'ID': list(range(1, 21)),\n",
    "        'Name': ['Employee'+str(i) for i in range(1, 21)],\n",
    "        'Department': ['Sales', 'Marketing', 'HR', 'Sales', 'IT', 'Marketing', 'HR', 'IT', 'Sales', 'Marketing',\n",
    "                    'HR', 'IT', 'Sales', 'Marketing', 'HR', 'IT', 'Sales', 'Marketing', 'HR', 'IT'],\n",
    "        'Start_Date': pd.date_range(start='01-01-2020', periods=20),\n",
    "        'Salary': [i*1000 for i in range(50, 70)]\n",
    "    }\n",
    "    df1 = pd.DataFrame(data1)\n",
    "\n",
    "    # Creating DataFrame df2\n",
    "    data2 = {\n",
    "        'Identifier': list(range(11, 31)),\n",
    "        'Role': ['Role'+str(i) for i in range(11, 31)],\n",
    "        'Years_of_Experience': [i for i in range(1, 21)]\n",
    "    }\n",
    "    df2 = pd.DataFrame(data2)\n",
    "\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write a line of code to perform an inner join of df1 and df2 on the ‘ID’ column.\n",
    "\n",
    "Note: The merge() function with how='inner' is useful for combining two DataFrames based on a common column, and only keeping rows that have matching values in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "# Performing an inner join on 'ID'\n",
    "df3 = df1.merge(df2, left_on='ID', right_on='Identifier', how='inner')\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a line of code to perform an outer join of df1 and df2 on the ‘ID’ column.\n",
    "\n",
    "Note: The merge() function with how='outer' is useful for combining two DataFrames based on a common column, and keeping all rows from both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "# Performing an outer join on 'ID'\n",
    "df3 = df1.merge(df2, left_on='ID', right_on='Identifier', how='outer')\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a line of code to join df1 and df2 on different column names (‘ID’ in df1 and ‘Identifier’ in df2).\n",
    "\n",
    "Note: The merge() function with left_on and right_on parameters is useful for combining two DataFrames based on different column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "# Joining on different column names\n",
    "df3 = df1.merge(df2, left_on='ID', right_on='Identifier')\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write a line of code to join df1 and df2 on their indices.\n",
    "\n",
    "Note: The join() function is useful for combining two DataFrames based on their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "# Joining on indices\n",
    "df3 = df1.join(df2, how='inner', lsuffix='_df1', rsuffix='_df2')\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write a line of code to perform a left join of df1 and df2 on the ‘ID’ column.\n",
    "\n",
    "Note: The merge() function with how='left' is useful for combining two DataFrames based on a common column, and keeping all rows from the left DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "# Performing a left join on 'ID'\n",
    "df3 = df1.merge(df2, left_on='ID', right_on='Identifier', how='left')\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Write a line of code to perform a right join of df1 and df2 on the ‘ID’ column.\n",
    "\n",
    "Note: The merge() function with how='right' is useful for combining two DataFrames based on a common column, and keeping all rows from the right DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "# Performing a right join on 'ID'\n",
    "df3 = df1.merge(df2, left_on='ID', right_on='Identifier', how='right')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Write a line of code to join df1 and df2 on the ‘ID’ column, where ‘ID’ is the index in df1 and a regular column in df2.\n",
    "\n",
    "Note: The combination of the .set_index() function and the .join() function is useful when you want to join two DataFrames based on an index in one DataFrame and a regular column in another DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "# Joining on index in df1 and regular column in df2\n",
    "df3 = df1.set_index('ID').join(df2.set_index('Identifier'), how='inner').reset_index()\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Write a line of code to join df1 and df2, where ‘ID’ is a regular column in both DataFrames, but treat it as an index only for the purpose of joining.\n",
    "\n",
    "Note: The combination of the .set_index(), .join(), and .reset_index() functions is useful when you want to join two DataFrames based on a common column, but don’t want this column to be the index in your resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "# Joining on 'ID' treated as index\n",
    "df3 = df1.set_index('ID').join(df2.set_index('Identifier'), how='inner').reset_index()\n",
    "df3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
